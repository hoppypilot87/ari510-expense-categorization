{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e903c028",
   "metadata": {},
   "source": [
    "<H1 align=\"center\"> Automated Expense Categorization - Notebook 02: Baseline Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f720f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "915262de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a12a5f2",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe25cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/transactions_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "965c5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Step 2.1: Label Encoding for Categories\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "category_map = {\n",
    "    'Groceries': 1,\n",
    "    'Eating_Out': 2,\n",
    "    'Entertainment': 3,\n",
    "    'Transport': 4,\n",
    "    'Utilities': 5,\n",
    "    'Healthcare': 6,\n",
    "    'Education': 7,\n",
    "    'Miscellaneous': 8\n",
    "\n",
    "}\n",
    "df['category_encoded'] = df['category'].map(category_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0a599",
   "metadata": {},
   "source": [
    "## 3. Define featues and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb7b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Step 3.1: Predict Amount for Savings\n",
    "#   Remove non-numeric columns and target variable\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "x_savings = df.drop(columns=[\"Desired_Savings\", \"entity_id\", \"Occupation\", \"City_Tier\", \"category\"])\n",
    "y_savings = df[\"Desired_Savings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e693257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Step 3.2 Predict Overspending\n",
    "#   Remove non-numeric columns and target variable\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "df[\"Overspend_Flag\"] = (df[\"amount\"] > df[\"Disposable_Income\"]).astype(int)\n",
    "x_spending = df.drop(columns=[\"Overspend_Flag\", \"entity_id\", \"category\", \"Occupation\", \"City_Tier\", \"category\"])\n",
    "y_spending = df[\"Overspend_Flag\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b43c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 3.3 Predict Spending Category\n",
    "# # ----------------------------------------------------------\n",
    "# future_spending = [\n",
    "    \n",
    "# ]\n",
    "# y_future_spending = df[future_spending]\n",
    "# x_future_soending = pd.get_dummies(df, columns=[\"category\"], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9494c2",
   "metadata": {},
   "source": [
    "# 4. Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d420f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 4.1 Split data for savings category\n",
    "# # ----------------------------------------------------------\n",
    "# Split 80% training/ 20% testing\n",
    "\n",
    "X_savings_train, X_savings_test, y_savings_train, y_savings_test = train_test_split(\n",
    "    x_savings, \n",
    "    y_savings, \n",
    "    test_size=0.2, \n",
    "    random_state=42     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3770d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 4.2 Split data for overspending category \n",
    "# # ----------------------------------------------------------\n",
    "# Split 80% training/ 20% testing\n",
    "\n",
    "X_spending_train, X_spending_test, y_spending_train, y_spending_test = train_test_split(\n",
    "    x_spending, \n",
    "    y_spending, \n",
    "    test_size=0.2, \n",
    "    random_state=42     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b8a4bc",
   "metadata": {},
   "source": [
    "# 5. Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "682ae290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 5.1 Scale features for savings model\n",
    "# # ----------------------------------------------------------\n",
    "\n",
    "scaler_s = StandardScaler()\n",
    "scaler_s.fit(X_savings_train)\n",
    "\n",
    "X_savings_train_scaled = scaler_s.transform(X_savings_train)\n",
    "X_savings_test_scaled = scaler_s.transform(X_savings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d790242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 5.2 Scale features for overspending model\n",
    "# # ----------------------------------------------------------\n",
    "\n",
    "scaler_s = StandardScaler()\n",
    "scaler_s.fit(X_spending_train)\n",
    "\n",
    "X_spending_train_scaled = scaler_s.transform(X_spending_train)\n",
    "X_spending_test_scaled = scaler_s.transform(X_spending_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19c0a4",
   "metadata": {},
   "source": [
    "# 6. Baseline models\n",
    " - Linear Regression\n",
    " - Linear SVM\n",
    " - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "186ce8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 6.1 Linear Regression for Savings Prediction\n",
    "# # ----------------------------------------------------------\n",
    "lr_savings = LinearRegression()\n",
    "lr_savings.fit(X_savings_train_scaled, y_savings_train)\n",
    "\n",
    "y_savings_pred_lr = lr_savings.predict(X_savings_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60069bf",
   "metadata": {},
   "source": [
    "SVM Model <br>\n",
    "Expensive to run: O(n^2) to O(n^3) <br>\n",
    "\\>7min\n",
    "<br> Speed is a known constraint of linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a257bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 6.2 Linear SVM for Savings Prediction\n",
    "# # ----------------------------------------------------------\n",
    "\n",
    "svm_linear_savings = SVR(kernel='linear')\n",
    "svm_linear_savings.fit(X_savings_train_scaled, y_savings_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b9a2e",
   "metadata": {},
   "source": [
    "Random Forest Configuration\n",
    " - Added all default values for possible configuration\n",
    " - Investigation needed into fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 6.3 Random Forest for Savings Prediction\n",
    "# # ----------------------------------------------------------\n",
    "\n",
    "rf_savings = RandomForestRegressor(\n",
    "    n_estimators=100,              # Number of trees in the forest\n",
    "    criterion='squared_error',     # Function to measure the quality of a split ('squared_error' for regression)\n",
    "    max_depth=None,                # No maximum depth; trees expand until all leaves are pure\n",
    "    min_samples_split=2,           # Minimum samples required to split a node\n",
    "    min_samples_leaf=1,            # Minimum samples required at a leaf node\n",
    "    min_weight_fraction_leaf=0.0,  # Minimum weighted fraction of the sum total of weights required to be at a leaf node\n",
    "    max_features=1.0,              # Number of features to consider when looking for best split\n",
    "    max_leaf_nodes=None,           # Unlimited leaf nodes\n",
    "    min_impurity_decrease=0.0,     # Minimum impurity decrease required to split a node\n",
    "    bootstrap=True,                # Whether bootstrap samples are used when building trees\n",
    "    oob_score=False,               # Whether to use out-of-bag samples to estimate R^2\n",
    "    n_jobs=None,                   # Number of CPU cores to use (None = 1 core)\n",
    "    random_state=None,             # Seed for reproducibility\n",
    "    verbose=0,                     # Verbosity level (0 = silent)\n",
    "    warm_start=False,              # Reuse previous solution to add more estimators\n",
    "    ccp_alpha=0.0,                 # Complexity parameter for Minimal Cost-Complexity Pruning\n",
    "    max_samples=None,              # Number (or fraction) of samples to draw for each tree if bootstrap=True\n",
    ")\n",
    "\n",
    "\n",
    "rf_savings.fit(X_savings_train_scaled, y_savings_train)\n",
    "y_savings_pred_rf = rf_savings.predict(X_savings_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c23c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 6.4 Linear Regression for Spending Prediction\n",
    "# # ----------------------------------------------------------\n",
    "lr_spending = LinearRegression()\n",
    "lr_spending.fit(X_spending_train_scaled, y_spending_train)\n",
    "\n",
    "y_spending_pred_lr = lr_spending.predict(X_spending_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 6.5 Linear SVM for Spending Prediction\n",
    "# # ----------------------------------------------------------\n",
    "\n",
    "# !!!!! Added max_iter to avoid timeout \n",
    "\n",
    "svm_spending = SVR(kernel='linear')\n",
    "svm_spending.fit(X_spending_train_scaled, y_spending_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86415baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 6.6 Random Forest for Spending Prediction\n",
    "# # ----------------------------------------------------------\n",
    "\n",
    "rf_spending = RandomForestRegressor(\n",
    "    n_estimators=100,              # Number of trees in the forest\n",
    "    criterion='squared_error',     # Function to measure the quality of a split ('squared_error' for regression)\n",
    "    max_depth=None,                # No maximum depth; trees expand until all leaves are pure\n",
    "    min_samples_split=2,           # Minimum samples required to split a node\n",
    "    min_samples_leaf=1,            # Minimum samples required at a leaf node\n",
    "    min_weight_fraction_leaf=0.0,  # Minimum weighted fraction of the sum total of weights required to be at a leaf node\n",
    "    max_features=1.0,              # Number of features to consider when looking for best split\n",
    "    max_leaf_nodes=None,           # Unlimited leaf nodes\n",
    "    min_impurity_decrease=0.0,     # Minimum impurity decrease required to split a node\n",
    "    bootstrap=True,                # Whether bootstrap samples are used when building trees\n",
    "    oob_score=False,               # Whether to use out-of-bag samples to estimate R^2\n",
    "    n_jobs=None,                   # Number of CPU cores to use (None = 1 core)\n",
    "    random_state=None,             # Seed for reproducibility\n",
    "    verbose=0,                     # Verbosity level (0 = silent)\n",
    "    warm_start=False,              # Reuse previous solution to add more estimators\n",
    "    ccp_alpha=0.0,                 # Complexity parameter for Minimal Cost-Complexity Pruning\n",
    "    max_samples=None,              # Number (or fraction) of samples to draw for each tree if bootstrap=True\n",
    "    monotonic_cst=None             # Monotonic constraints (rarely used)\n",
    ")\n",
    "\n",
    "\n",
    "rf_spending.fit(X_spending_train_scaled, y_spending_train)\n",
    "y_spending_pred_rf = rf_spending.predict(X_spending_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d4b63",
   "metadata": {},
   "source": [
    "# 7. Evaluate Models\n",
    "1. Regression model evaluation\n",
    "    - Mean Absolute Error\n",
    "    - Mean Squared Error\n",
    "    - Root Mean Squated Error\n",
    "    - Coefficient of Determination\n",
    "2. Classifiaction model evaluation\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550fd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Savings prediction (Linear Regression) metrics:\n",
      "{'MAE': 1367.3062541404454, 'MSE': 4752452.789736879, 'RMSE': np.float64(2180.012107704193), 'R2': 0.9268700960784603}\n",
      "Savings prediction (Random Forest) metrics:\n",
      "{'MAE': 1.3267414643144364, 'MSE': 537.7841964851087, 'RMSE': np.float64(23.190174567801527), 'R2': 0.9999917246717939}\n",
      "\n",
      "Spending Linear Regression (thresholded) Results:\n",
      "Accuracy: 0.9611068359625496\n",
      "Precision: 0.6981132075471698\n",
      "Recall: 0.029983792544570502\n",
      "F1-score: 0.057498057498057496\n",
      "\n",
      "Confusion Matrix:\n",
      " [[29938    16]\n",
      " [ 1197    37]]\n",
      "\n",
      "Detailed Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     29954\n",
      "           1       0.70      0.03      0.06      1234\n",
      "\n",
      "    accuracy                           0.96     31188\n",
      "   macro avg       0.83      0.51      0.52     31188\n",
      "weighted avg       0.95      0.96      0.94     31188\n",
      "\n",
      "\n",
      "Spending Random Forest (thresholded) Results:\n",
      "Accuracy: 0.9981403103757855\n",
      "Precision: 0.9867549668874173\n",
      "Recall: 0.965964343598055\n",
      "F1-score: 0.9762489762489762\n",
      "\n",
      "Confusion Matrix:\n",
      " [[29938    16]\n",
      " [   42  1192]]\n",
      "\n",
      "Detailed Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     29954\n",
      "           1       0.99      0.97      0.98      1234\n",
      "\n",
      "    accuracy                           1.00     31188\n",
      "   macro avg       0.99      0.98      0.99     31188\n",
      "weighted avg       1.00      1.00      1.00     31188\n",
      "\n",
      "\n",
      "Logistic Regression (classifier) Results:\n",
      "Accuracy: 0.9938758496857766\n",
      "Precision: 0.9728014505893019\n",
      "Recall: 0.8695299837925445\n",
      "F1-score: 0.9182712879760376\n",
      "\n",
      "Confusion Matrix:\n",
      " [[29924    30]\n",
      " [  161  1073]]\n",
      "\n",
      "Detailed Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     29954\n",
      "           1       0.97      0.87      0.92      1234\n",
      "\n",
      "    accuracy                           0.99     31188\n",
      "   macro avg       0.98      0.93      0.96     31188\n",
      "weighted avg       0.99      0.99      0.99     31188\n",
      "\n",
      "\n",
      "Random Forest (classifier) Results:\n",
      "Accuracy: 0.9950942670257792\n",
      "Precision: 0.9770520741394528\n",
      "Recall: 0.8970826580226904\n",
      "F1-score: 0.935361216730038\n",
      "\n",
      "Confusion Matrix:\n",
      " [[29928    26]\n",
      " [  127  1107]]\n",
      "\n",
      "Detailed Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     29954\n",
      "           1       0.98      0.90      0.94      1234\n",
      "\n",
      "    accuracy                           1.00     31188\n",
      "   macro avg       0.99      0.95      0.97     31188\n",
      "weighted avg       1.00      1.00      0.99     31188\n",
      "\n",
      "\n",
      "Logistic Regression ROC AUC: 0.99957603820185\n"
     ]
    }
   ],
   "source": [
    "# Evaluation: Regression (Savings) and Classification (Overspend)\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "print(\"Savings prediction (Linear Regression) metrics:\")\n",
    "metrics_lr = regression_metrics(y_savings_test, y_savings_pred_lr)\n",
    "print(metrics_lr)\n",
    "\n",
    "print(\"Savings prediction (Random Forest) metrics:\")\n",
    "metrics_rf = regression_metrics(y_savings_test, y_savings_pred_rf)\n",
    "print(metrics_rf)\n",
    "\n",
    "try:\n",
    "    X_train_cls = X_spending_train_scaled\n",
    "    X_test_cls = X_spending_test_scaled\n",
    "    y_train_cls = y_spending_train\n",
    "    y_test_cls = y_spending_test\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Spending train/test variables not found in notebook state\")\n",
    "\n",
    "y_spend_pred_lr_cont = globals().get('y_spending_pred_lr', None)\n",
    "y_spend_pred_rf_cont = globals().get('y_spending_pred_rf', None)\n",
    "\n",
    "def classification_eval(y_true, y_pred, name='Model'):\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, zero_division=0))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred, zero_division=0))\n",
    "    print(\"F1-score:\", f1_score(y_true, y_pred, zero_division=0))\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nDetailed Report:\\n\", classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "if y_spend_pred_lr_cont is not None:\n",
    "    y_pred_lr_bin = (np.array(y_spend_pred_lr_cont) >= 0.5).astype(int)\n",
    "    classification_eval(y_test_cls, y_pred_lr_bin, name='Spending Linear Regression (thresholded)')\n",
    "\n",
    "if y_spend_pred_rf_cont is not None:\n",
    "    y_pred_rf_bin = (np.array(y_spend_pred_rf_cont) >= 0.5).astype(int)\n",
    "    classification_eval(y_test_cls, y_pred_rf_bin, name='Spending Random Forest (thresholded)')\n",
    "\n",
    "log_clf = LogisticRegression(max_iter=1000)\n",
    "log_clf.fit(X_train_cls, y_train_cls)\n",
    "y_pred_log = log_clf.predict(X_test_cls)\n",
    "classification_eval(y_test_cls, y_pred_log, name='Logistic Regression (classifier)')\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train_cls, y_train_cls)\n",
    "y_pred_rf_clf = rf_clf.predict(X_test_cls)\n",
    "classification_eval(y_test_cls, y_pred_rf_clf, name='Random Forest (classifier)')\n",
    "\n",
    "if hasattr(log_clf, 'predict_proba'):\n",
    "    try:\n",
    "        y_proba = log_clf.predict_proba(X_test_cls)[:, 1]\n",
    "        auc = roc_auc_score(y_test_cls, y_proba)\n",
    "        print(\"\\nLogistic Regression ROC AUC:\", auc)\n",
    "    except ValueError:\n",
    "        print(\"\\nROC AUC could not be computed (single class present in y_test)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a343f",
   "metadata": {},
   "source": [
    "# 8. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880c1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
