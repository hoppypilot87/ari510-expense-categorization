{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1882840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook ready ✅\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 03_model_tuning.ipynb\n",
    "# Purpose: Hyperparameter tuning and cross-validation\n",
    "# ===============================================================\n",
    "print(\"Notebook ready ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19881ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# safe to re-run\n",
    "%pip install -q ipywidgets tqdm tqdm-joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b31e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 03_model_tuning.ipynb\n",
    "# Purpose: Hyperparameter tuning (CV) for Savings regression\n",
    "# ================================================================\n",
    "\n",
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Distributions\n",
    "from scipy.stats import loguniform, randint\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Cross-validation setup\n",
    "CV_FOLDS = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Explicit RMSE scorer (safe across sklearn versions)\n",
    "rmse_scorer = make_scorer(\n",
    "    lambda yt, yp: -float(np.sqrt(mean_squared_error(yt, yp))),\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "def eval_regression(est, X_test, y_test):\n",
    "    \"\"\"Compute evaluation metrics for a fitted regression estimator.\"\"\"\n",
    "    y_pred = est.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = float(np.mean((y_test - y_pred) ** 2))\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mae, mse, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3caf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Savings shapes: (124751, 17) (31188, 17)\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Load processed dataset\n",
    "# ================================================================\n",
    "DATA_PATH = \"../data/processed/transactions_long.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "target_col = \"Desired_Savings\"\n",
    "drop_cols = [\"entity_id\", \"category\", \"Occupation\", \"City_Tier\", target_col]\n",
    "num_cols = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\").select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "X_savings = df[num_cols].copy()\n",
    "y_savings = df[target_col].astype(float).copy()\n",
    "\n",
    "# Train/test split\n",
    "X_savings_train, X_savings_test, y_savings_train, y_savings_test = train_test_split(\n",
    "    X_savings, y_savings, test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Savings shapes:\", X_savings_train.shape, X_savings_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92598854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Tuning setup (run once, above 5A) ===\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import loguniform, randint\n",
    "\n",
    "# Repro + CV config\n",
    "SEED      = 42\n",
    "CV_FOLDS  = 5            # k-folds\n",
    "N_ITER_REG = 24          # param samples per model (adjust to speed up/slow down)\n",
    "N_JOBS     = -1          # use all cores\n",
    "\n",
    "# Pipelines / estimators\n",
    "svr_pipe = make_pipeline(\n",
    "    # scale for SVR\n",
    "    StandardScaler(),\n",
    "    LinearSVR(dual=True,  # default True; good when n_samples > n_features\n",
    "              tol=1e-3,\n",
    "              max_iter=5000,\n",
    "              random_state=SEED)\n",
    ")\n",
    "\n",
    "rf_reg = RandomForestRegressor(\n",
    "    random_state=SEED,\n",
    "    n_jobs=N_JOBS\n",
    ")\n",
    "\n",
    "# Parameter distributions for RandomizedSearchCV\n",
    "# (SVR): search C and epsilon on log scales; keep loss=\"epsilon_insensitive\" default\n",
    "svr_dist = {\n",
    "    \"linearsvr__C\":       loguniform(1e-2, 1e2),\n",
    "    \"linearsvr__epsilon\": loguniform(1e-3, 1.0),\n",
    "}\n",
    "\n",
    "# (RandomForest): moderate ranges to keep runtime reasonable\n",
    "rf_dist = {\n",
    "    \"n_estimators\":   randint(50, 200),\n",
    "    \"max_depth\":      randint(6, 18),\n",
    "    \"min_samples_split\": randint(2, 8),\n",
    "    \"min_samples_leaf\":  randint(1, 6),\n",
    "    \"max_features\":      [\"sqrt\", \"log2\"],\n",
    "    \"bootstrap\":         [True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74799afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "► Running CV for regression: SVR (Savings)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180095808ea644d998f06b12a35ef42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SVR (Savings) tuning:   0%|          | 0/36 [00:00<?, ?fits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV (neg RMSE): -2868.0748 | Params: {'linearsvr__epsilon': np.float64(0.3897685379286406), 'linearsvr__C': np.float64(36.06389385521764)}\n",
      "Fit time: 0.06s\n",
      "\n",
      "► Running CV for regression: RandomForest (Savings)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41485c57bd234b9690b7106272b8c9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RandomForest (Savings) tuning:   0%|          | 0/180 [00:00<?, ?fits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV (neg RMSE): -666.4141 | Params: {'n_estimators': np.int64(110), 'min_samples_split': np.int64(2), 'min_samples_leaf': np.int64(1), 'max_features': 'sqrt', 'max_depth': np.int64(14), 'bootstrap': True}\n",
      "Fit time: 8.81s\n",
      "\n",
      "=== Savings → Regression (test set) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (best)</td>\n",
       "      <td>146.344882</td>\n",
       "      <td>2.931481e+05</td>\n",
       "      <td>541.431512</td>\n",
       "      <td>0.995489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVR (best)</td>\n",
       "      <td>1043.811580</td>\n",
       "      <td>1.004005e+07</td>\n",
       "      <td>3168.603360</td>\n",
       "      <td>0.845506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model          MAE           MSE         RMSE        R2\n",
       "1  Random Forest (best)   146.344882  2.931481e+05   541.431512  0.995489\n",
       "0            SVR (best)  1043.811580  1.004005e+07  3168.603360  0.845506"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 5A. Run grid/random searches (REGRESSION: Savings) ======================\n",
    "# Fast knobs + progress bar CV search for SVR and RandomForest\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import (\n",
    "    KFold, cross_val_score, ParameterSampler\n",
    ")\n",
    "\n",
    "# ---------- tuning knobs (fast) ----------\n",
    "SEED       = 42\n",
    "N_JOBS     = -1\n",
    "CV_FOLDS   = 3         # 3-fold during tuning; keep 5-fold for final checks\n",
    "N_ITER_REG = 12        # #param samples per model (fast but useful)\n",
    "\n",
    "rng = np.random.RandomState(SEED)\n",
    "cv  = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=SEED)\n",
    "scoring = 'neg_root_mean_squared_error'  # RMSE (negative)\n",
    "\n",
    "# ---------- subsample features for tuning only ----------\n",
    "def maybe_subsample(X, y, frac=0.35, random_state=SEED):\n",
    "    n = int(len(y) * frac)\n",
    "    idx = rng.choice(len(y), n, replace=False)\n",
    "    return X.iloc[idx] if hasattr(X, \"iloc\") else X[idx], y.iloc[idx] if hasattr(y, \"iloc\") else y[idx]\n",
    "\n",
    "X_savings_train_t, y_savings_train_t = maybe_subsample(X_savings_train, y_savings_train, frac=0.35, random_state=SEED)\n",
    "\n",
    "# ---------- estimators + distributions (narrower = faster & stabler) ----------\n",
    "svr_pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearSVR(dual=True, tol=1e-3, max_iter=5000, random_state=SEED)\n",
    ")\n",
    "svr_dist = {\n",
    "    \"linearsvr__C\":       np.exp(rng.uniform(np.log(1e-2), np.log(1e2), size=N_ITER_REG*2)),  # pre-sampled log-uniform\n",
    "    \"linearsvr__epsilon\": np.exp(rng.uniform(np.log(5e-2), np.log(5e-1), size=N_ITER_REG*2)),\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor(\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=SEED\n",
    ")\n",
    "rf_dist = {\n",
    "    \"n_estimators\":      rng.randint(60, 141, size=N_ITER_REG*2),  # 60–140\n",
    "    \"max_depth\":         rng.randint(6, 15,  size=N_ITER_REG*2),   # 6–14\n",
    "    \"min_samples_split\": rng.randint(2, 7,   size=N_ITER_REG*2),   # 2–6\n",
    "    \"min_samples_leaf\":  rng.randint(1, 5,   size=N_ITER_REG*2),   # 1–4\n",
    "    \"max_features\":      [\"sqrt\"],                                  # drop \"log2\" to prune space\n",
    "    \"bootstrap\":         [True],\n",
    "}\n",
    "\n",
    "def param_sampler(dist, n_iter, rng):\n",
    "    \"\"\"\n",
    "    Turn our arrays/lists into a ParameterSampler-friendly dict.\n",
    "    If a value is an array/list, sample uniformly; if a scalar, use as-is.\n",
    "    \"\"\"\n",
    "    space = {}\n",
    "    for k, v in dist.items():\n",
    "        if isinstance(v, (list, np.ndarray)):\n",
    "            space[k] = v\n",
    "        else:\n",
    "            space[k] = [v]\n",
    "    return ParameterSampler(space, n_iter=n_iter, random_state=rng)\n",
    "\n",
    "def manual_cv_search(label, base_est, dist, X, y, n_iter=N_ITER_REG):\n",
    "    \"\"\"\n",
    "    Simple manual CV search with a tqdm progress bar.\n",
    "    Updates progress by CV_FOLDS per parameter set (so total = n_iter*CV_FOLDS).\n",
    "    Returns: best_estimator, best_cv_rmse, best_params, fit_time\n",
    "    \"\"\"\n",
    "    sampler = list(param_sampler(dist, n_iter, rng))\n",
    "    pbar = tqdm(total=len(sampler)*CV_FOLDS, desc=f\"{label} tuning\", unit=\"fits\")\n",
    "    best_rmse = np.inf\n",
    "    best_params = None\n",
    "\n",
    "    for params in sampler:\n",
    "        est = clone(base_est).set_params(**params)\n",
    "        # run k-fold CV (note: we update by CV_FOLDS for this set)\n",
    "        scores = cross_val_score(est, X, y, scoring=scoring, cv=cv, n_jobs=N_JOBS)\n",
    "        rmse = -np.mean(scores)\n",
    "        pbar.update(CV_FOLDS)\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse   = rmse\n",
    "            best_params = deepcopy(params)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # Fit best on *full* (subsampled) training\n",
    "    best = clone(base_est).set_params(**best_params)\n",
    "    t0 = time.perf_counter()\n",
    "    best.fit(X, y)\n",
    "    fit_time = time.perf_counter() - t0\n",
    "\n",
    "    print(f\"Best CV (neg RMSE): {-best_rmse:.4f} | Params: {best_params}\")\n",
    "    print(f\"Fit time: {fit_time:.2f}s\")\n",
    "    return best, -best_rmse, best_params, fit_time  # return positive score for readability\n",
    "\n",
    "# ---------- run searches ----------\n",
    "print(\"\\n► Running CV for regression: SVR (Savings)\")\n",
    "best_svr, best_svr_score, best_svr_params, _ = manual_cv_search(\n",
    "    \"SVR (Savings)\", svr_pipe, svr_dist, X_savings_train_t, y_savings_train_t, n_iter=N_ITER_REG\n",
    ")\n",
    "\n",
    "print(\"\\n► Running CV for regression: RandomForest (Savings)\")\n",
    "best_rf, best_rf_score, best_rf_params, _ = manual_cv_search(\n",
    "    \"RandomForest (Savings)\", rf_reg, rf_dist, X_savings_train_t, y_savings_train_t, n_iter=N_ITER_REG*5  # a bit more budget\n",
    ")\n",
    "\n",
    "# ---------- evaluate on the held-out test set (full, not subsampled) ----------\n",
    "def evaluate_best(name, est, X_test, y_test):\n",
    "    from math import sqrt\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    y_pred = est.predict(X_test)\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "    mse  = mean_squared_error(y_test, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "    return {\"Model\": name, \"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "rows = []\n",
    "rows.append(evaluate_best(\"SVR (best)\",         best_svr, X_savings_test, y_savings_test))\n",
    "rows.append(evaluate_best(\"Random Forest (best)\", best_rf, X_savings_test, y_savings_test))\n",
    "\n",
    "reg_results_df = pd.DataFrame(rows).sort_values(\"RMSE\")\n",
    "print(\"\\n=== Savings → Regression (test set) ===\")\n",
    "display(reg_results_df)\n",
    "\n",
    "# keep for later summary cell if needed\n",
    "best_svr_savings     = best_svr\n",
    "best_svr_savings_cv  = best_svr_score\n",
    "best_rf_savings      = best_rf\n",
    "best_rf_savings_cv   = best_rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f5149ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CLASSIFICATION: Expense Category Prediction (Multi-class)\n",
      "======================================================================\n",
      "\n",
      "Dataset for category classification:\n",
      "  Features (X): (155939, 18)\n",
      "  Target classes: 8 → ['Eating_Out', 'Education', 'Entertainment', 'Groceries', 'Healthcare', 'Miscellaneous', 'Transport', 'Utilities']\n",
      "  Class distribution:\n",
      "0    20000\n",
      "1    15939\n",
      "2    20000\n",
      "3    20000\n",
      "4    20000\n",
      "5    20000\n",
      "6    20000\n",
      "7    20000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train shape: (124751, 18) | Test shape: (31188, 18)\n",
      "\n",
      "► Tuning Logistic Regression (Category)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f32348844b746abab0111b150905340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LogReg (Category) tuning:   0%|          | 0/45 [00:00<?, ?fits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best CV (f1_macro): 0.4890\n",
      "  Best params: {'solver': 'lbfgs', 'class_weight': None, 'C': np.float64(75.7947995334801)}\n",
      "  Fit time: 21.65s\n",
      "\n",
      "► Tuning Linear SVC (Category)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c27a3139f0f48d29a0a207d9cc54dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LinearSVC (Category) tuning:   0%|          | 0/45 [00:00<?, ?fits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best CV (f1_macro): 0.3991\n",
      "  Best params: {'C': np.float64(13.826232179369875)}\n",
      "  Fit time: 275.03s\n",
      "\n",
      "► Tuning Random Forest (Category)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c72f40a914468b919452ed0836dc0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RandomForest (Category) tuning:   0%|          | 0/90 [00:00<?, ?fits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best CV (f1_macro): 0.4198\n",
      "  Best params: {'n_estimators': np.int64(139), 'min_samples_split': np.int64(3), 'min_samples_leaf': np.int64(4), 'max_features': 'sqrt', 'max_depth': np.int64(12)}\n",
      "  Fit time: 30.98s\n",
      "\n",
      "======================================================================\n",
      "CLASSIFICATION TEST SET RESULTS\n",
      "======================================================================\n",
      "\n",
      "Category Classification Results (Test Set):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (macro)</th>\n",
       "      <th>Recall (macro)</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (best)</td>\n",
       "      <td>0.510773</td>\n",
       "      <td>0.492300</td>\n",
       "      <td>0.511121</td>\n",
       "      <td>0.489787</td>\n",
       "      <td>0.489009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (best)</td>\n",
       "      <td>0.471239</td>\n",
       "      <td>0.410746</td>\n",
       "      <td>0.468697</td>\n",
       "      <td>0.415909</td>\n",
       "      <td>0.415410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVC (best)</td>\n",
       "      <td>0.437444</td>\n",
       "      <td>0.425410</td>\n",
       "      <td>0.442923</td>\n",
       "      <td>0.394646</td>\n",
       "      <td>0.393984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Accuracy  Precision (macro)  Recall (macro)  \\\n",
       "0  Logistic Regression (best)  0.510773           0.492300        0.511121   \n",
       "2        Random Forest (best)  0.471239           0.410746        0.468697   \n",
       "1           Linear SVC (best)  0.437444           0.425410        0.442923   \n",
       "\n",
       "   F1 (macro)  F1 (weighted)  \n",
       "0    0.489787       0.489009  \n",
       "2    0.415909       0.415410  \n",
       "1    0.394646       0.393984  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest - Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Eating_Out       0.17      0.06      0.09      4000\n",
      "    Education       0.53      0.37      0.44      3188\n",
      "Entertainment       0.16      0.06      0.08      4000\n",
      "    Groceries       0.91      0.99      0.95      4000\n",
      "   Healthcare       0.34      0.69      0.46      4000\n",
      "Miscellaneous       0.62      0.86      0.72      4000\n",
      "    Transport       0.40      0.66      0.50      4000\n",
      "    Utilities       0.15      0.06      0.09      4000\n",
      "\n",
      "     accuracy                           0.47     31188\n",
      "    macro avg       0.41      0.47      0.42     31188\n",
      " weighted avg       0.41      0.47      0.42     31188\n",
      "\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred: Eating_Out</th>\n",
       "      <th>Pred: Education</th>\n",
       "      <th>Pred: Entertainment</th>\n",
       "      <th>Pred: Groceries</th>\n",
       "      <th>Pred: Healthcare</th>\n",
       "      <th>Pred: Miscellaneous</th>\n",
       "      <th>Pred: Transport</th>\n",
       "      <th>Pred: Utilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True: Eating_Out</th>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "      <td>2060</td>\n",
       "      <td>1027</td>\n",
       "      <td>39</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True: Education</th>\n",
       "      <td>1</td>\n",
       "      <td>1183</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1466</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True: Entertainment</th>\n",
       "      <td>489</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>2</td>\n",
       "      <td>2117</td>\n",
       "      <td>1004</td>\n",
       "      <td>38</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True: Groceries</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True: Healthcare</th>\n",
       "      <td>472</td>\n",
       "      <td>2</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>2746</td>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True: Miscellaneous</th>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True: Transport</th>\n",
       "      <td>7</td>\n",
       "      <td>613</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>2638</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True: Utilities</th>\n",
       "      <td>18</td>\n",
       "      <td>434</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>940</td>\n",
       "      <td>0</td>\n",
       "      <td>2340</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Pred: Eating_Out  Pred: Education  Pred: Entertainment  \\\n",
       "True: Eating_Out                  244                0                  463   \n",
       "True: Education                     1             1183                    2   \n",
       "True: Entertainment               489                0                  232   \n",
       "True: Groceries                     0               18                    0   \n",
       "True: Healthcare                  472                2                  430   \n",
       "True: Miscellaneous               237                0                  317   \n",
       "True: Transport                     7              613                    6   \n",
       "True: Utilities                    18              434                   16   \n",
       "\n",
       "                     Pred: Groceries  Pred: Healthcare  Pred: Miscellaneous  \\\n",
       "True: Eating_Out                   0              2060                 1027   \n",
       "True: Education                  333                50                    0   \n",
       "True: Entertainment                2              2117                 1004   \n",
       "True: Groceries                 3976                 0                    0   \n",
       "True: Healthcare                   0              2746                   38   \n",
       "True: Miscellaneous                0                 7                 3439   \n",
       "True: Transport                   23                80                    0   \n",
       "True: Utilities                   13               940                    0   \n",
       "\n",
       "                     Pred: Transport  Pred: Utilities  \n",
       "True: Eating_Out                  39              167  \n",
       "True: Education                 1466              153  \n",
       "True: Entertainment               38              118  \n",
       "True: Groceries                    5                1  \n",
       "True: Healthcare                  60              252  \n",
       "True: Miscellaneous                0                0  \n",
       "True: Transport                 2638              633  \n",
       "True: Utilities                 2340              239  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification model tuning complete!\n",
      "   Best model saved: best_rf_clf (Random Forest)\n",
      "   Best CV score (macro F1): 0.4198\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 5B. Classification Model Tuning: Expense Category Prediction\n",
    "#     Build and tune classifiers to predict spending category\n",
    "# ================================================================\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION: Expense Category Prediction (Multi-class)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ---------- Prepare classification dataset ----------\n",
    "# Load original data if not already loaded\n",
    "if \"df\" not in globals():\n",
    "    DATA_PATH = \"../data/processed/transactions_long.csv\"\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "TARGET_CAT = \"category\"\n",
    "ID_COLS = {\"entity_id\", \"txn_id\", \"index\", \"id\"}\n",
    "drop_for_clf = [c for c in df.columns if c in ID_COLS or (\"category_encoded\" in c)]\n",
    "\n",
    "# Extract features and target\n",
    "X_category = df.drop(columns=drop_for_clf, errors=\"ignore\").select_dtypes(include=[np.number]).copy()\n",
    "y_category_raw = df[TARGET_CAT].copy()\n",
    "\n",
    "# Encode category labels\n",
    "le_cat = LabelEncoder()\n",
    "y_category = le_cat.fit_transform(y_category_raw)\n",
    "\n",
    "print(f\"\\nDataset for category classification:\")\n",
    "print(f\"  Features (X): {X_category.shape}\")\n",
    "print(f\"  Target classes: {len(le_cat.classes_)} → {list(le_cat.classes_)}\")\n",
    "print(f\"  Class distribution:\\n{pd.Series(y_category, index=y_category_raw.index).value_counts().sort_index()}\\n\")\n",
    "\n",
    "# ---------- Train/test split with stratification ----------\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_cat_train, X_cat_test, y_cat_train, y_cat_test = train_test_split(\n",
    "    X_category, y_category, test_size=0.2, random_state=SEED, stratify=y_category\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_cat_train.shape} | Test shape: {X_cat_test.shape}\")\n",
    "\n",
    "# ---------- Scale features for fair comparison ----------\n",
    "scaler_cat = StandardScaler()\n",
    "scaler_cat.fit(X_cat_train)\n",
    "X_cat_train_scaled = scaler_cat.transform(X_cat_train)\n",
    "X_cat_test_scaled = scaler_cat.transform(X_cat_test)\n",
    "\n",
    "# ---------- Tuning configuration ----------\n",
    "CV_FOLDS_CAT = 3          # 3-fold CV during tuning (fast)\n",
    "N_ITER_CLF = 15           # parameter samples per classifier\n",
    "N_JOBS = -1\n",
    "\n",
    "rng_cat = np.random.RandomState(SEED)\n",
    "cv_cat = StratifiedKFold(n_splits=CV_FOLDS_CAT, shuffle=True, random_state=SEED)\n",
    "scoring_clf = 'f1_macro'  # macro F1 for imbalanced multi-class\n",
    "\n",
    "# ---------- Estimators + parameter distributions ----------\n",
    "\n",
    "# 1. Logistic Regression (multinomial)\n",
    "log_clf = LogisticRegression(\n",
    "    max_iter=1000, multi_class='multinomial', \n",
    "    random_state=SEED, n_jobs=N_JOBS\n",
    ")\n",
    "log_dist = {\n",
    "    \"C\": np.exp(rng_cat.uniform(np.log(1e-2), np.log(1e2), size=N_ITER_CLF)),\n",
    "    \"solver\": [\"lbfgs\"],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "# 2. Linear SVC (one-vs-rest)\n",
    "svc_clf = LinearSVC(\n",
    "    dual=True, max_iter=2000, tol=1e-3,\n",
    "    random_state=SEED, class_weight='balanced'\n",
    ")\n",
    "svc_dist = {\n",
    "    \"C\": np.exp(rng_cat.uniform(np.log(1e-2), np.log(1e2), size=N_ITER_CLF)),\n",
    "}\n",
    "\n",
    "# 3. Random Forest (multi-class by default)\n",
    "rf_clf = RandomForestClassifier(\n",
    "    random_state=SEED, n_jobs=N_JOBS\n",
    ")\n",
    "rf_dist = {\n",
    "    \"n_estimators\": rng_cat.randint(50, 151, size=N_ITER_CLF),\n",
    "    \"max_depth\": rng_cat.randint(6, 16, size=N_ITER_CLF),\n",
    "    \"min_samples_split\": rng_cat.randint(2, 8, size=N_ITER_CLF),\n",
    "    \"min_samples_leaf\": rng_cat.randint(1, 5, size=N_ITER_CLF),\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "}\n",
    "\n",
    "# ---------- Helper: Manual CV search with progress bar ----------\n",
    "def param_sampler_helper(dist, n_iter, rng):\n",
    "    \"\"\"Convert distribution dict to ParameterSampler format.\"\"\"\n",
    "    from sklearn.model_selection import ParameterSampler\n",
    "    space = {}\n",
    "    for k, v in dist.items():\n",
    "        if isinstance(v, (list, np.ndarray)):\n",
    "            space[k] = v\n",
    "        else:\n",
    "            space[k] = [v]\n",
    "    return ParameterSampler(space, n_iter=n_iter, random_state=rng)\n",
    "\n",
    "def manual_cv_search_clf(label, base_est, dist, X, y, n_iter=N_ITER_CLF):\n",
    "    \"\"\"Manual CV search for classification with tqdm progress bar.\"\"\"\n",
    "    sampler = list(param_sampler_helper(dist, n_iter, rng_cat))\n",
    "    pbar = tqdm(total=len(sampler)*CV_FOLDS_CAT, desc=f\"{label} tuning\", unit=\"fits\")\n",
    "    \n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    \n",
    "    for params in sampler:\n",
    "        est = clone(base_est).set_params(**params)\n",
    "        try:\n",
    "            # Use macro F1 for multi-class fairness\n",
    "            scores = cross_val_score(est, X, y, scoring=scoring_clf, cv=cv_cat, n_jobs=N_JOBS)\n",
    "            score = np.mean(scores)\n",
    "        except Exception as e:\n",
    "            score = -np.inf\n",
    "            \n",
    "        pbar.update(CV_FOLDS_CAT)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = deepcopy(params)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Fit best model on full training set\n",
    "    best = clone(base_est).set_params(**best_params)\n",
    "    t0 = time.perf_counter()\n",
    "    best.fit(X, y)\n",
    "    fit_time = time.perf_counter() - t0\n",
    "    \n",
    "    print(f\"  Best CV ({scoring_clf}): {best_score:.4f}\")\n",
    "    print(f\"  Best params: {best_params}\")\n",
    "    print(f\"  Fit time: {fit_time:.2f}s\")\n",
    "    \n",
    "    return best, best_score, best_params\n",
    "\n",
    "# ---------- Run classification tuning ----------\n",
    "print(\"\\n► Tuning Logistic Regression (Category)...\")\n",
    "best_log_clf, best_log_score, best_log_params = manual_cv_search_clf(\n",
    "    \"LogReg (Category)\", log_clf, log_dist, X_cat_train_scaled, y_cat_train, n_iter=N_ITER_CLF\n",
    ")\n",
    "\n",
    "print(\"\\n► Tuning Linear SVC (Category)...\")\n",
    "best_svc_clf, best_svc_score, best_svc_params = manual_cv_search_clf(\n",
    "    \"LinearSVC (Category)\", svc_clf, svc_dist, X_cat_train_scaled, y_cat_train, n_iter=N_ITER_CLF\n",
    ")\n",
    "\n",
    "print(\"\\n► Tuning Random Forest (Category)...\")\n",
    "best_rf_clf, best_rf_score, best_rf_params = manual_cv_search_clf(\n",
    "    \"RandomForest (Category)\", rf_clf, rf_dist, X_cat_train_scaled, y_cat_train, n_iter=N_ITER_CLF*2\n",
    ")\n",
    "\n",
    "# ---------- Evaluate on test set ----------\n",
    "def evaluate_classifier(name, est, X_test, y_test, y_test_raw=None):\n",
    "    \"\"\"Evaluate and return metrics for a classification model.\"\"\"\n",
    "    y_pred = est.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (macro)\": precision_macro,\n",
    "        \"Recall (macro)\": recall_macro,\n",
    "        \"F1 (macro)\": f1_macro,\n",
    "        \"F1 (weighted)\": f1_weighted,\n",
    "    }, y_pred\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION TEST SET RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "clf_results = []\n",
    "clf_predictions = {}\n",
    "\n",
    "result_log, pred_log = evaluate_classifier(\n",
    "    \"Logistic Regression (best)\", best_log_clf, X_cat_test_scaled, y_cat_test\n",
    ")\n",
    "clf_results.append(result_log)\n",
    "clf_predictions[\"LogReg\"] = pred_log\n",
    "\n",
    "result_svc, pred_svc = evaluate_classifier(\n",
    "    \"Linear SVC (best)\", best_svc_clf, X_cat_test_scaled, y_cat_test\n",
    ")\n",
    "clf_results.append(result_svc)\n",
    "clf_predictions[\"LinearSVC\"] = pred_svc\n",
    "\n",
    "result_rf, pred_rf = evaluate_classifier(\n",
    "    \"Random Forest (best)\", best_rf_clf, X_cat_test_scaled, y_cat_test\n",
    ")\n",
    "clf_results.append(result_rf)\n",
    "clf_predictions[\"RandomForest\"] = pred_rf\n",
    "\n",
    "# Display results\n",
    "clf_results_df = pd.DataFrame(clf_results).sort_values(\"F1 (macro)\", ascending=False)\n",
    "print(\"\\nCategory Classification Results (Test Set):\")\n",
    "display(clf_results_df)\n",
    "\n",
    "# Store best model for later use\n",
    "best_clf_model = best_rf_clf  # Default to RF; can be changed based on preference\n",
    "best_clf_name = \"Random Forest\"\n",
    "\n",
    "# ---------- Show detailed report for best model ----------\n",
    "print(f\"\\n{best_clf_name} - Detailed Classification Report:\")\n",
    "print(classification_report(y_cat_test, pred_rf, target_names=le_cat.classes_, zero_division=0))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_cat_test, pred_rf)\n",
    "cm_df = pd.DataFrame(cm, index=[f\"True: {c}\" for c in le_cat.classes_],\n",
    "                      columns=[f\"Pred: {c}\" for c in le_cat.classes_])\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "display(cm_df)\n",
    "\n",
    "print(\"\\n✅ Classification model tuning complete!\")\n",
    "print(f\"   Best model saved: best_rf_clf (Random Forest)\")\n",
    "print(f\"   Best CV score (macro F1): {best_rf_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "394001fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tuned Model Summary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Best model</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test F1 (macro)</th>\n",
       "      <th>Test F1 (weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Savings (regression)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>146.344882</td>\n",
       "      <td>541.431512</td>\n",
       "      <td>0.995489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Category (multi-class)</td>\n",
       "      <td>Logistic Regression (best)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510773</td>\n",
       "      <td>0.489787</td>\n",
       "      <td>0.489009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Task                  Best model    Test MAE   Test RMSE  \\\n",
       "0    Savings (regression)               Random Forest  146.344882  541.431512   \n",
       "1  Category (multi-class)  Logistic Regression (best)         NaN         NaN   \n",
       "\n",
       "    Test R2  Test Accuracy  Test F1 (macro)  Test F1 (weighted)  \n",
       "0  0.995489            NaN              NaN                 NaN  \n",
       "1       NaN       0.510773         0.489787            0.489009  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Summary of tuned models\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# Savings regression (from 5A)\n",
    "summary_rows.append({\n",
    "    \"Task\": \"Savings (regression)\",\n",
    "    \"Best model\": \"Random Forest\",\n",
    "    \"Test MAE\": reg_results_df.loc[reg_results_df[\"Model\"]==\"Random Forest (best)\", \"MAE\"].item(),\n",
    "    \"Test RMSE\": reg_results_df.loc[reg_results_df[\"Model\"]==\"Random Forest (best)\", \"RMSE\"].item(),\n",
    "    \"Test R2\": reg_results_df.loc[reg_results_df[\"Model\"]==\"Random Forest (best)\", \"R2\"].item(),\n",
    "})\n",
    "\n",
    "# Category classification (from 5B)\n",
    "summary_rows.append({\n",
    "    \"Task\": \"Category (multi-class)\",\n",
    "    \"Best model\": clf_results_df.iloc[0][\"Model\"],\n",
    "    \"Test Accuracy\": clf_results_df.iloc[0][\"Accuracy\"],\n",
    "    \"Test F1 (macro)\": clf_results_df.iloc[0][\"F1 (macro)\"],\n",
    "    \"Test F1 (weighted)\": clf_results_df.iloc[0][\"F1 (weighted)\"],\n",
    "})\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "print(\"=== Tuned Model Summary ===\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3db49ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "../data/models/best_savings_rf.pkl\n",
      "../data/models/best_category_rf.pkl\n"
     ]
    }
   ],
   "source": [
    "# 7. Save best models for reuse\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "models_dir = Path(\"../data/models\")\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(best_rf_savings, models_dir / \"best_savings_rf.pkl\")\n",
    "joblib.dump(best_rf_clf,    models_dir / \"best_category_rf.pkl\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(models_dir / \"best_savings_rf.pkl\")\n",
    "print(models_dir / \"best_category_rf.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
