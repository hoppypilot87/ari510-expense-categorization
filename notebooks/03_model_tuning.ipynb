{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1882840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook ready ✅\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 03_model_tuning.ipynb\n",
    "# Purpose: Hyperparameter tuning and cross-validation\n",
    "# ===============================================================\n",
    "print(\"Notebook ready ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19881ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# safe to re-run\n",
    "%pip install -q ipywidgets tqdm tqdm-joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b31e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 03_model_tuning.ipynb\n",
    "# Purpose: Hyperparameter tuning (CV) for Savings regression\n",
    "# ================================================================\n",
    "\n",
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Distributions\n",
    "from scipy.stats import loguniform, randint\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Cross-validation setup\n",
    "CV_FOLDS = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Explicit RMSE scorer (safe across sklearn versions)\n",
    "rmse_scorer = make_scorer(\n",
    "    lambda yt, yp: -float(np.sqrt(mean_squared_error(yt, yp))),\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "def eval_regression(est, X_test, y_test):\n",
    "    \"\"\"Compute evaluation metrics for a fitted regression estimator.\"\"\"\n",
    "    y_pred = est.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = float(np.mean((y_test - y_pred) ** 2))\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mae, mse, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c3caf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Savings shapes: (124751, 17) (31188, 17)\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Load processed dataset\n",
    "# ================================================================\n",
    "DATA_PATH = \"../data/processed/transactions_long.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "target_col = \"Desired_Savings\"\n",
    "drop_cols = [\"entity_id\", \"category\", \"Occupation\", \"City_Tier\", target_col]\n",
    "num_cols = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\").select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "X_savings = df[num_cols].copy()\n",
    "y_savings = df[target_col].astype(float).copy()\n",
    "\n",
    "# Train/test split\n",
    "X_savings_train, X_savings_test, y_savings_train, y_savings_test = train_test_split(\n",
    "    X_savings, y_savings, test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Savings shapes:\", X_savings_train.shape, X_savings_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92598854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Tuning setup (run once, above 5A) ===\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import loguniform, randint\n",
    "\n",
    "# Repro + CV config\n",
    "SEED      = 42\n",
    "CV_FOLDS  = 5            # k-folds\n",
    "N_ITER_REG = 24          # param samples per model (adjust to speed up/slow down)\n",
    "N_JOBS     = -1          # use all cores\n",
    "\n",
    "# Pipelines / estimators\n",
    "svr_pipe = make_pipeline(\n",
    "    # scale for SVR\n",
    "    StandardScaler(),\n",
    "    LinearSVR(dual=True,  # default True; good when n_samples > n_features\n",
    "              tol=1e-3,\n",
    "              max_iter=5000,\n",
    "              random_state=SEED)\n",
    ")\n",
    "\n",
    "rf_reg = RandomForestRegressor(\n",
    "    random_state=SEED,\n",
    "    n_jobs=N_JOBS\n",
    ")\n",
    "\n",
    "# Parameter distributions for RandomizedSearchCV\n",
    "# (SVR): search C and epsilon on log scales; keep loss=\"epsilon_insensitive\" default\n",
    "svr_dist = {\n",
    "    \"linearsvr__C\":       loguniform(1e-2, 1e2),\n",
    "    \"linearsvr__epsilon\": loguniform(1e-3, 1.0),\n",
    "}\n",
    "\n",
    "# (RandomForest): moderate ranges to keep runtime reasonable\n",
    "rf_dist = {\n",
    "    \"n_estimators\":   randint(50, 200),\n",
    "    \"max_depth\":      randint(6, 18),\n",
    "    \"min_samples_split\": randint(2, 8),\n",
    "    \"min_samples_leaf\":  randint(1, 6),\n",
    "    \"max_features\":      [\"sqrt\", \"log2\"],\n",
    "    \"bootstrap\":         [True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74799afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "► Running CV for regression: SVR (Savings)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b93cad55614cc3bc22608263ee5d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SVR (Savings) tuning:   0%|          | 0/36 [00:00<?, ?fits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV (neg RMSE): -2868.0748 | Params: {'linearsvr__epsilon': np.float64(0.3897685379286406), 'linearsvr__C': np.float64(36.06389385521764)}\n",
      "Fit time: 0.06s\n",
      "\n",
      "► Running CV for regression: RandomForest (Savings)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613423c1825e420e8111ea8655420acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RandomForest (Savings) tuning:   0%|          | 0/180 [00:00<?, ?fits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV (neg RMSE): -666.4141 | Params: {'n_estimators': np.int64(110), 'min_samples_split': np.int64(2), 'min_samples_leaf': np.int64(1), 'max_features': 'sqrt', 'max_depth': np.int64(14), 'bootstrap': True}\n",
      "Fit time: 8.92s\n",
      "\n",
      "=== Savings → Regression (test set) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (best)</td>\n",
       "      <td>146.344882</td>\n",
       "      <td>2.931481e+05</td>\n",
       "      <td>541.431512</td>\n",
       "      <td>0.995489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVR (best)</td>\n",
       "      <td>1043.811580</td>\n",
       "      <td>1.004005e+07</td>\n",
       "      <td>3168.603360</td>\n",
       "      <td>0.845506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model          MAE           MSE         RMSE        R2\n",
       "1  Random Forest (best)   146.344882  2.931481e+05   541.431512  0.995489\n",
       "0            SVR (best)  1043.811580  1.004005e+07  3168.603360  0.845506"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 5A. Run grid/random searches (REGRESSION: Savings) ======================\n",
    "# Fast knobs + progress bar CV search for SVR and RandomForest\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import (\n",
    "    KFold, cross_val_score, ParameterSampler\n",
    ")\n",
    "\n",
    "# ---------- tuning knobs (fast) ----------\n",
    "SEED       = 42\n",
    "N_JOBS     = -1\n",
    "CV_FOLDS   = 3         # 3-fold during tuning; keep 5-fold for final checks\n",
    "N_ITER_REG = 12        # #param samples per model (fast but useful)\n",
    "\n",
    "rng = np.random.RandomState(SEED)\n",
    "cv  = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=SEED)\n",
    "scoring = 'neg_root_mean_squared_error'  # RMSE (negative)\n",
    "\n",
    "# ---------- optional: subsample features for tuning only ----------\n",
    "def maybe_subsample(X, y, frac=0.35, random_state=SEED):\n",
    "    n = int(len(y) * frac)\n",
    "    idx = rng.choice(len(y), n, replace=False)\n",
    "    return X.iloc[idx] if hasattr(X, \"iloc\") else X[idx], y.iloc[idx] if hasattr(y, \"iloc\") else y[idx]\n",
    "\n",
    "X_savings_train_t, y_savings_train_t = maybe_subsample(X_savings_train, y_savings_train, frac=0.35, random_state=SEED)\n",
    "\n",
    "# ---------- estimators + distributions (narrower = faster & stabler) ----------\n",
    "svr_pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearSVR(dual=True, tol=1e-3, max_iter=5000, random_state=SEED)\n",
    ")\n",
    "svr_dist = {\n",
    "    \"linearsvr__C\":       np.exp(rng.uniform(np.log(1e-2), np.log(1e2), size=N_ITER_REG*2)),  # pre-sampled log-uniform\n",
    "    \"linearsvr__epsilon\": np.exp(rng.uniform(np.log(5e-2), np.log(5e-1), size=N_ITER_REG*2)),\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor(\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=SEED\n",
    ")\n",
    "rf_dist = {\n",
    "    \"n_estimators\":      rng.randint(60, 141, size=N_ITER_REG*2),  # 60–140\n",
    "    \"max_depth\":         rng.randint(6, 15,  size=N_ITER_REG*2),   # 6–14\n",
    "    \"min_samples_split\": rng.randint(2, 7,   size=N_ITER_REG*2),   # 2–6\n",
    "    \"min_samples_leaf\":  rng.randint(1, 5,   size=N_ITER_REG*2),   # 1–4\n",
    "    \"max_features\":      [\"sqrt\"],                                  # drop \"log2\" to prune space\n",
    "    \"bootstrap\":         [True],\n",
    "}\n",
    "\n",
    "def param_sampler(dist, n_iter, rng):\n",
    "    \"\"\"\n",
    "    Turn our arrays/lists into a ParameterSampler-friendly dict.\n",
    "    If a value is an array/list, sample uniformly; if a scalar, use as-is.\n",
    "    \"\"\"\n",
    "    space = {}\n",
    "    for k, v in dist.items():\n",
    "        if isinstance(v, (list, np.ndarray)):\n",
    "            space[k] = v\n",
    "        else:\n",
    "            space[k] = [v]\n",
    "    return ParameterSampler(space, n_iter=n_iter, random_state=rng)\n",
    "\n",
    "def manual_cv_search(label, base_est, dist, X, y, n_iter=N_ITER_REG):\n",
    "    \"\"\"\n",
    "    Simple manual CV search with a tqdm progress bar.\n",
    "    Updates progress by CV_FOLDS per parameter set (so total = n_iter*CV_FOLDS).\n",
    "    Returns: best_estimator, best_cv_rmse, best_params, fit_time\n",
    "    \"\"\"\n",
    "    sampler = list(param_sampler(dist, n_iter, rng))\n",
    "    pbar = tqdm(total=len(sampler)*CV_FOLDS, desc=f\"{label} tuning\", unit=\"fits\")\n",
    "    best_rmse = np.inf\n",
    "    best_params = None\n",
    "\n",
    "    for params in sampler:\n",
    "        est = clone(base_est).set_params(**params)\n",
    "        # run k-fold CV (note: we update by CV_FOLDS for this set)\n",
    "        scores = cross_val_score(est, X, y, scoring=scoring, cv=cv, n_jobs=N_JOBS)\n",
    "        rmse = -np.mean(scores)\n",
    "        pbar.update(CV_FOLDS)\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse   = rmse\n",
    "            best_params = deepcopy(params)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # Fit best on *full* (subsampled) training\n",
    "    best = clone(base_est).set_params(**best_params)\n",
    "    t0 = time.perf_counter()\n",
    "    best.fit(X, y)\n",
    "    fit_time = time.perf_counter() - t0\n",
    "\n",
    "    print(f\"Best CV (neg RMSE): {-best_rmse:.4f} | Params: {best_params}\")\n",
    "    print(f\"Fit time: {fit_time:.2f}s\")\n",
    "    return best, -best_rmse, best_params, fit_time  # return positive score for readability\n",
    "\n",
    "# ---------- run searches ----------\n",
    "print(\"\\n► Running CV for regression: SVR (Savings)\")\n",
    "best_svr, best_svr_score, best_svr_params, _ = manual_cv_search(\n",
    "    \"SVR (Savings)\", svr_pipe, svr_dist, X_savings_train_t, y_savings_train_t, n_iter=N_ITER_REG\n",
    ")\n",
    "\n",
    "print(\"\\n► Running CV for regression: RandomForest (Savings)\")\n",
    "best_rf, best_rf_score, best_rf_params, _ = manual_cv_search(\n",
    "    \"RandomForest (Savings)\", rf_reg, rf_dist, X_savings_train_t, y_savings_train_t, n_iter=N_ITER_REG*5  # a bit more budget\n",
    ")\n",
    "\n",
    "# ---------- evaluate on the held-out test set (full, not subsampled) ----------\n",
    "def evaluate_best(name, est, X_test, y_test):\n",
    "    from math import sqrt\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    y_pred = est.predict(X_test)\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "    mse  = mean_squared_error(y_test, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "    return {\"Model\": name, \"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "rows = []\n",
    "rows.append(evaluate_best(\"SVR (best)\",         best_svr, X_savings_test, y_savings_test))\n",
    "rows.append(evaluate_best(\"Random Forest (best)\", best_rf, X_savings_test, y_savings_test))\n",
    "\n",
    "reg_results_df = pd.DataFrame(rows).sort_values(\"RMSE\")\n",
    "print(\"\\n=== Savings → Regression (test set) ===\")\n",
    "display(reg_results_df)\n",
    "\n",
    "# keep for later summary cell if needed\n",
    "best_svr_savings     = best_svr\n",
    "best_svr_savings_cv  = best_svr_score\n",
    "best_rf_savings      = best_rf\n",
    "best_rf_savings_cv   = best_rf_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
