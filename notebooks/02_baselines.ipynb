{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e903c028",
   "metadata": {},
   "source": [
    "<H1 align=\"center\"> Automated Expense Categorization - Notebook 02: Baseline Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f720f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "## 1. Setup\n",
    "Import libraries, lock randomness for reproducibility, and set light config so results are stable and readable across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "915262de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready âœ…  |  numpy 2.3.4 | pandas 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# --- Setup: imports, config, reproducibility ---------------------------------\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd          # tables / DataFrames\n",
    "import numpy as np           # numerical ops (arrays, math)\n",
    "\n",
    "# Modeling + evaluation\n",
    "from sklearn.model_selection import train_test_split   # split train/test\n",
    "from sklearn.preprocessing import StandardScaler       # feature scaling\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import LinearSVC                      # fast linear SVM (classification)\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import (                          # metrics for both tasks\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "\n",
    "# Housekeeping\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Reproducibility: set all seeds so results are repeatable across runs\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Quiet overly verbose warnings so the notebook stays readable\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Small pandas display tweaks for nicer tables in the notebook\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "print(\"Environment ready âœ…  |  numpy\", np.__version__, \"| pandas\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a12a5f2",
   "metadata": {},
   "source": [
    "## 2. Load data\n",
    "In this step, we import the processed long-format transaction dataset created in Notebook 01.\n",
    "Weâ€™ll also apply basic integrity checks to confirm the file exists, loads correctly, and the key columns (like category) are present before encoding them for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe25cf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded dataset: 155,939 rows Ã— 22 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Tier</th>\n",
       "      <th>Rent</th>\n",
       "      <th>Loan_Repayment</th>\n",
       "      <th>Insurance</th>\n",
       "      <th>Desired_Savings_Percentage</th>\n",
       "      <th>Desired_Savings</th>\n",
       "      <th>Disposable_Income</th>\n",
       "      <th>Potential_Savings_Groceries</th>\n",
       "      <th>Potential_Savings_Transport</th>\n",
       "      <th>Potential_Savings_Eating_Out</th>\n",
       "      <th>Potential_Savings_Entertainment</th>\n",
       "      <th>Potential_Savings_Utilities</th>\n",
       "      <th>Potential_Savings_Healthcare</th>\n",
       "      <th>Potential_Savings_Education</th>\n",
       "      <th>Potential_Savings_Miscellaneous</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44637.249636</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>Tier_1</td>\n",
       "      <td>13391.174891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2206.490129</td>\n",
       "      <td>13.890948</td>\n",
       "      <td>6200.537192</td>\n",
       "      <td>11265.627707</td>\n",
       "      <td>1685.696222</td>\n",
       "      <td>328.895281</td>\n",
       "      <td>465.769172</td>\n",
       "      <td>195.151320</td>\n",
       "      <td>678.292859</td>\n",
       "      <td>67.682471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.735517</td>\n",
       "      <td>0</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>6658.768341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26858.596592</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Tier_2</td>\n",
       "      <td>5371.719318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>869.522617</td>\n",
       "      <td>7.160376</td>\n",
       "      <td>1923.176434</td>\n",
       "      <td>9676.818733</td>\n",
       "      <td>540.306561</td>\n",
       "      <td>119.347139</td>\n",
       "      <td>141.866089</td>\n",
       "      <td>234.131168</td>\n",
       "      <td>286.668408</td>\n",
       "      <td>6.603212</td>\n",
       "      <td>56.306874</td>\n",
       "      <td>97.388606</td>\n",
       "      <td>1</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>2818.444460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50367.605084</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>Student</td>\n",
       "      <td>Tier_3</td>\n",
       "      <td>7555.140763</td>\n",
       "      <td>4612.103386</td>\n",
       "      <td>2201.800050</td>\n",
       "      <td>13.997808</td>\n",
       "      <td>7050.360422</td>\n",
       "      <td>13891.450624</td>\n",
       "      <td>1466.073984</td>\n",
       "      <td>473.549752</td>\n",
       "      <td>410.857129</td>\n",
       "      <td>459.965256</td>\n",
       "      <td>488.383423</td>\n",
       "      <td>7.290892</td>\n",
       "      <td>106.653597</td>\n",
       "      <td>138.542422</td>\n",
       "      <td>2</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>6313.222081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101455.600247</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>Tier_3</td>\n",
       "      <td>15218.340037</td>\n",
       "      <td>6809.441427</td>\n",
       "      <td>4889.418087</td>\n",
       "      <td>16.455440</td>\n",
       "      <td>16694.965136</td>\n",
       "      <td>31617.953615</td>\n",
       "      <td>1875.932770</td>\n",
       "      <td>762.020789</td>\n",
       "      <td>1241.017448</td>\n",
       "      <td>320.190594</td>\n",
       "      <td>1389.815033</td>\n",
       "      <td>193.502754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>296.041183</td>\n",
       "      <td>3</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>14690.149363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24875.283548</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Tier_2</td>\n",
       "      <td>4975.056710</td>\n",
       "      <td>3112.609398</td>\n",
       "      <td>635.907170</td>\n",
       "      <td>7.533982</td>\n",
       "      <td>1874.099434</td>\n",
       "      <td>6265.700532</td>\n",
       "      <td>788.953124</td>\n",
       "      <td>68.160766</td>\n",
       "      <td>61.712505</td>\n",
       "      <td>187.173750</td>\n",
       "      <td>194.117130</td>\n",
       "      <td>47.294591</td>\n",
       "      <td>67.388120</td>\n",
       "      <td>96.557076</td>\n",
       "      <td>4</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>3034.329665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Income  Age  Dependents     Occupation City_Tier          Rent  Loan_Repayment    Insurance  \\\n",
       "0   44637.249636   49           0  Self_Employed    Tier_1  13391.174891        0.000000  2206.490129   \n",
       "1   26858.596592   34           2        Retired    Tier_2   5371.719318        0.000000   869.522617   \n",
       "2   50367.605084   35           1        Student    Tier_3   7555.140763     4612.103386  2201.800050   \n",
       "3  101455.600247   21           0  Self_Employed    Tier_3  15218.340037     6809.441427  4889.418087   \n",
       "4   24875.283548   52           4   Professional    Tier_2   4975.056710     3112.609398   635.907170   \n",
       "\n",
       "   Desired_Savings_Percentage  Desired_Savings  Disposable_Income  Potential_Savings_Groceries  \\\n",
       "0                   13.890948      6200.537192       11265.627707                  1685.696222   \n",
       "1                    7.160376      1923.176434        9676.818733                   540.306561   \n",
       "2                   13.997808      7050.360422       13891.450624                  1466.073984   \n",
       "3                   16.455440     16694.965136       31617.953615                  1875.932770   \n",
       "4                    7.533982      1874.099434        6265.700532                   788.953124   \n",
       "\n",
       "   Potential_Savings_Transport  Potential_Savings_Eating_Out  Potential_Savings_Entertainment  \\\n",
       "0                   328.895281                    465.769172                       195.151320   \n",
       "1                   119.347139                    141.866089                       234.131168   \n",
       "2                   473.549752                    410.857129                       459.965256   \n",
       "3                   762.020789                   1241.017448                       320.190594   \n",
       "4                    68.160766                     61.712505                       187.173750   \n",
       "\n",
       "   Potential_Savings_Utilities  Potential_Savings_Healthcare  Potential_Savings_Education  \\\n",
       "0                   678.292859                     67.682471                     0.000000   \n",
       "1                   286.668408                      6.603212                    56.306874   \n",
       "2                   488.383423                      7.290892                   106.653597   \n",
       "3                  1389.815033                    193.502754                     0.000000   \n",
       "4                   194.117130                     47.294591                    67.388120   \n",
       "\n",
       "   Potential_Savings_Miscellaneous  entity_id   category        amount  \n",
       "0                        85.735517          0  Groceries   6658.768341  \n",
       "1                        97.388606          1  Groceries   2818.444460  \n",
       "2                       138.542422          2  Groceries   6313.222081  \n",
       "3                       296.041183          3  Groceries  14690.149363  \n",
       "4                        96.557076          4  Groceries   3034.329665  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Step 2: Load the processed transaction dataset ---------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Define dataset path relative to this notebook\n",
    "csv_path = Path(\"../data/processed/transactions_long.csv\")\n",
    "\n",
    "# Verify that the file exists before reading\n",
    "if not csv_path.exists():\n",
    "    raise FileNotFoundError(f\"âŒ Dataset not found at: {csv_path}. \"\n",
    "                            \"Please ensure Notebook 01 has been run successfully.\")\n",
    "\n",
    "# Load dataset into pandas DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"âœ… Loaded dataset: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "display(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "febd8b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique categories and encoded values:\n",
      "             category  category_encoded\n",
      "0           Groceries                 1\n",
      "40000      Eating_Out                 2\n",
      "60000   Entertainment                 3\n",
      "20000       Transport                 4\n",
      "80000       Utilities                 5\n",
      "100000     Healthcare                 6\n",
      "120000      Education                 7\n",
      "135939  Miscellaneous                 8\n",
      "âœ… All categories successfully encoded.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2.1: Label-encode spending categories -------------------------------\n",
    "# Weâ€™ll convert category names (e.g., â€œGroceriesâ€) into numeric IDs for ML models.\n",
    "# This keeps the mapping consistent across notebooks.\n",
    "\n",
    "category_map = {\n",
    "    \"Groceries\": 1,\n",
    "    \"Eating_Out\": 2,\n",
    "    \"Entertainment\": 3,\n",
    "    \"Transport\": 4,\n",
    "    \"Utilities\": 5,\n",
    "    \"Healthcare\": 6,\n",
    "    \"Education\": 7,\n",
    "    \"Miscellaneous\": 8\n",
    "}\n",
    "\n",
    "# Apply label encoding safely\n",
    "df[\"category_encoded\"] = df[\"category\"].map(category_map)\n",
    "\n",
    "# Confirm encoding worked as expected\n",
    "print(\"\\nUnique categories and encoded values:\")\n",
    "print(df[[\"category\", \"category_encoded\"]].drop_duplicates().sort_values(\"category_encoded\"))\n",
    "\n",
    "# Quick sanity check â€” ensure no missing encodings\n",
    "if df[\"category_encoded\"].isnull().any():\n",
    "    missing = df.loc[df[\"category_encoded\"].isnull(), \"category\"].unique()\n",
    "    print(f\"âš ï¸ Warning: Missing encodings for {len(missing)} categories: {missing}\")\n",
    "else:\n",
    "    print(\"âœ… All categories successfully encoded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0a599",
   "metadata": {},
   "source": [
    "## 3. Define featues and target\n",
    "In this step, we separate our input features (X) and target variables (y) for each prediction task. Specifically, we create datasets for predicting Desired Savings (regression) and Overspending (classification), removing ID and non-numeric columns to prevent data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfb7b456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¦ Savings task\n",
      "Features: ['Income', 'Age', 'Dependents', 'Rent', 'Loan_Repayment', 'Insurance', 'Desired_Savings_Percentage', 'Disposable_Income', 'Potential_Savings_Groceries', 'Potential_Savings_Transport', 'Potential_Savings_Eating_Out', 'Potential_Savings_Entertainment', 'Potential_Savings_Utilities', 'Potential_Savings_Healthcare', 'Potential_Savings_Education', 'Potential_Savings_Miscellaneous', 'amount']\n",
      "Shape X/y: (155939, 17) / (155939,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Define features & targets ---------------------------------------\n",
    "import numpy as np\n",
    "\n",
    "# Columns that should never be used as features (IDs / target / leakage)\n",
    "ID_OR_TARGET = {\"entity_id\", \"txn_id\", \"txn_index\", \"category\", \"category_encoded\",\n",
    "                \"Desired_Savings\", \"Overspend_Flag\"}\n",
    "\n",
    "# Helper: choose numeric features safely and drop forbidden columns\n",
    "def make_feature_matrix(df, extra_drop=None):\n",
    "    extra_drop = set(extra_drop or [])\n",
    "    drop_these = ID_OR_TARGET.union(extra_drop)\n",
    "\n",
    "    # Keep only numeric columns to avoid accidental text/categorical leakage\n",
    "    numeric_df = df.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "    # Drop forbidden columns if present\n",
    "    X = numeric_df.drop(columns=[c for c in drop_these if c in numeric_df.columns], errors=\"ignore\")\n",
    "    return X\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3.1 Predict Amount for Savings  (Regression)\n",
    "#    Target: Desired_Savings  (continuous)\n",
    "# ---------------------------------------------------------------------------\n",
    "TARGET_SAVINGS = \"Desired_Savings\"\n",
    "if TARGET_SAVINGS not in df.columns:\n",
    "    raise KeyError(f\"Missing target column: {TARGET_SAVINGS}\")\n",
    "\n",
    "X_savings = make_feature_matrix(df, extra_drop={TARGET_SAVINGS})\n",
    "y_savings = df[TARGET_SAVINGS].astype(float)\n",
    "\n",
    "print(\"ðŸŸ¦ Savings task\")\n",
    "print(\"Features:\", list(X_savings.columns))\n",
    "print(f\"Shape X/y: {X_savings.shape} / {y_savings.shape}\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e693257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ© Overspending task\n",
      "Features: ['Income', 'Age', 'Dependents', 'Rent', 'Loan_Repayment', 'Insurance', 'Desired_Savings_Percentage', 'Disposable_Income', 'Potential_Savings_Groceries', 'Potential_Savings_Transport', 'Potential_Savings_Eating_Out', 'Potential_Savings_Entertainment', 'Potential_Savings_Utilities', 'Potential_Savings_Healthcare', 'Potential_Savings_Education', 'Potential_Savings_Miscellaneous', 'amount']\n",
      "Class balance (0=no overspend, 1=overspend): {0: 149921, 1: 6018}\n",
      "Shape X/y: (155939, 17) / (155939,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 3.2 Predict Overspending  (Classification)\n",
    "#    Target: Overspend_Flag  (0/1)\n",
    "# ---------------------------------------------------------------------------\n",
    "TARGET_SPENDING = \"Overspend_Flag\"\n",
    "if TARGET_SPENDING not in df.columns:\n",
    "    # If not present, derive a simple label: overspent if amount > disposable income\n",
    "    # (Adjust this rule as needed for your project definition.)\n",
    "    df[TARGET_SPENDING] = (df[\"amount\"] > df[\"Disposable_Income\"]).astype(int)\n",
    "\n",
    "X_spending = make_feature_matrix(df, extra_drop={TARGET_SPENDING})\n",
    "y_spending = df[TARGET_SPENDING].astype(int)\n",
    "\n",
    "print(\"ðŸŸ© Overspending task\")\n",
    "print(\"Features:\", list(X_spending.columns))\n",
    "# Class balance check to inform model choice & class_weight usage\n",
    "class_counts = y_spending.value_counts().sort_index()\n",
    "print(f\"Class balance (0=no overspend, 1=overspend): {class_counts.to_dict()}\")\n",
    "print(f\"Shape X/y: {X_spending.shape} / {y_spending.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 3.3 Predict Spending Category  (Multiclass Classification)\n",
    "#    Target: category_encoded  (1..K)\n",
    "#    This is scaffolded for later; uncomment if you want to train now.\n",
    "# ---------------------------------------------------------------------------\n",
    "# TARGET_CAT = \"category_encoded\"\n",
    "# if TARGET_CAT not in df.columns:\n",
    "#     raise KeyError(\"category_encoded not found. Ensure Step 2 label-encoding ran.\")\n",
    "#\n",
    "# # Drop targets/IDs; you may also drop current-row 'amount' to avoid trivial leakage\n",
    "# X_future_spending = make_feature_matrix(df, extra_drop={TARGET_CAT, \"amount\"})\n",
    "# y_future_spending = df[TARGET_CAT].astype(int)\n",
    "#\n",
    "# print(\"ðŸŸ¨ Category task (optional)\")\n",
    "# print(\"Features:\", list(X_future_spending.columns))\n",
    "# print(f\"Shape X/y: {X_future_spending.shape} / {y_future_spending.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9494c2",
   "metadata": {},
   "source": [
    "# 4. Split data into train and test\n",
    "We divide each dataset into training and testing subsets, using an 80/20 split. This ensures that our models learn patterns from one portion of the data and are evaluated on unseen data to measure generalization performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6d420f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 4. Split Data into Train and Test\n",
    "#    - Savings: regression target â†’ standard split\n",
    "#    - Overspending: binary target â†’ stratified split to preserve class balance\n",
    "# ===============================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---- 4.1 Savings (Regression) ----\n",
    "X_savings_train, X_savings_test, y_savings_train, y_savings_test = train_test_split(\n",
    "    X_savings,\n",
    "    y_savings,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3770d148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Savings shapes: (124751, 17) (31188, 17) (124751,) (31188,)\n",
      "Spending shapes: (124751, 17) (31188, 17) (124751,) (31188,)\n",
      "Spending class balance (train/test): {0: 0.961411130972898, 1: 0.038588869027101985} {0: 0.961395408490445, 1: 0.038604591509554954}\n"
     ]
    }
   ],
   "source": [
    "# ---- 4.2 Overspending (Classification) ----\n",
    "# Use stratify to keep the 0/1 ratio similar in train and test sets.\n",
    "X_spending_train, X_spending_test, y_spending_train, y_spending_test = train_test_split(\n",
    "    X_spending,\n",
    "    y_spending,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_spending\n",
    ")\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Savings shapes:\", X_savings_train.shape, X_savings_test.shape, y_savings_train.shape, y_savings_test.shape)\n",
    "print(\"Spending shapes:\", X_spending_train.shape, X_spending_test.shape, y_spending_train.shape, y_spending_test.shape)\n",
    "print(\"Spending class balance (train/test):\",\n",
    "      y_spending_train.value_counts(normalize=True).to_dict(),\n",
    "      y_spending_test.value_counts(normalize=True).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b8a4bc",
   "metadata": {},
   "source": [
    "# 5. Scale\n",
    "To ensure fair model comparisons and prevent features with larger numeric ranges from dominating the learning process, we apply standardization using StandardScaler. This step transforms each feature to have a mean of 0 and standard deviation of 1, improving the performance of models like SVM and Linear Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "682ae290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 5. Scale Features\n",
    "#    Standardize inputs to improve model convergence and stability.\n",
    "# ===============================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---- 5.1 Scale features for Savings Model ----\n",
    "scaler_savings = StandardScaler()\n",
    "scaler_savings.fit(X_savings_train)\n",
    "\n",
    "X_savings_train_scaled = scaler_savings.transform(X_savings_train)\n",
    "X_savings_test_scaled = scaler_savings.transform(X_savings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d790242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Savings scaled shape: (124751, 17) (31188, 17)\n",
      "Spending scaled shape: (124751, 17) (31188, 17)\n"
     ]
    }
   ],
   "source": [
    "# ---- 5.2 Scale features for Overspending Model ----\n",
    "scaler_spending = StandardScaler()\n",
    "scaler_spending.fit(X_spending_train)\n",
    "\n",
    "X_spending_train_scaled = scaler_spending.transform(X_spending_train)\n",
    "X_spending_test_scaled = scaler_spending.transform(X_spending_test)\n",
    "\n",
    "# ---- Quick verification ----\n",
    "print(\"Savings scaled shape:\", X_savings_train_scaled.shape, X_savings_test_scaled.shape)\n",
    "print(\"Spending scaled shape:\", X_spending_train_scaled.shape, X_spending_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19c0a4",
   "metadata": {},
   "source": [
    "# 6. Baseline models\n",
    "We train fast, interpretable baselines to set a performance floor. For Savings (a regression task), we use Linear Regression, a fast LinearSVR (via a pipeline that handles scaling), and a small RandomForestRegressor tuned for speed. For Overspending (a binary classification task), we try LinearSVC (linear margin classifier) and RandomForestClassifier. Hyperparameters are intentionally modest to avoid Codespaces timeoutsâ€”these are yardsticks, not tuned finalists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6a42f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 6. Baseline Models\n",
    "# ---------------------------------------------------------------\n",
    "# Baseline 1: Linear Regression / Linear SVC (fast, interpretable)\n",
    "# Baseline 2: Random Forest (non-linear, captures interactions)\n",
    "# ---------------------------------------------------------------\n",
    "# Separate models for:\n",
    "#   (a) Savings Prediction  -> Regression\n",
    "#   (b) Overspending         -> Classification\n",
    "# ===============================================================\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR, LinearSVC\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "186ce8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Linear Regression (Savings) complete.\n"
     ]
    }
   ],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 6.1 Linear Regression for Savings Prediction\n",
    "# # ----------------------------------------------------------\n",
    "\n",
    "lr_savings = LinearRegression()\n",
    "lr_savings.fit(X_savings_train_scaled, y_savings_train)\n",
    "\n",
    "y_savings_pred_lr = lr_savings.predict(X_savings_test_scaled)\n",
    "print(\"âœ… Linear Regression (Savings) complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60069bf",
   "metadata": {},
   "source": [
    "SVM Model <br>\n",
    "Expensive to run: O(n^2) to O(n^3) <br>\n",
    "\\>7min\n",
    "<br> Speed is a known constraint of linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a257bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LinearSVR fit+predict completed in 0.11s\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Step 6.2: Fast Linear SVR for Savings Prediction\n",
    "# ===============================================================\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVR\n",
    "from time import perf_counter\n",
    "\n",
    "# â± Measure runtime to compare performance\n",
    "t0 = perf_counter()\n",
    "\n",
    "# Build pipeline: Standardize âžœ LinearSVR\n",
    "svr_fast = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearSVR(C=1.0, epsilon=0.1, max_iter=5000, tol=1e-3)  # dual=True by default âœ…\n",
    ")\n",
    "\n",
    "# Train on unscaled features (pipeline handles scaling internally)\n",
    "svr_fast.fit(X_savings_train, y_savings_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_savings_pred_linSVR = svr_fast.predict(X_savings_test)\n",
    "\n",
    "print(f\"âœ… LinearSVR fit+predict completed in {perf_counter()-t0:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b9a2e",
   "metadata": {},
   "source": [
    "Random Forest Configuration\n",
    " - Added all default values for possible configuration\n",
    " - Investigation needed into fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab7b938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RandomForestRegressor fit+predict in 8.9s\n"
     ]
    }
   ],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 6.3 Random Forest for Savings Prediction\n",
    "# # ----------------------------------------------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np, time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "rf_savings = RandomForestRegressor(\n",
    "    n_estimators=50,          # trees\n",
    "    max_depth=12,             # limit depth for faster runtime\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=\"sqrt\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf_savings.fit(X_savings_train, y_savings_train)\n",
    "y_savings_pred_rf = rf_savings.predict(X_savings_test)\n",
    "print(f\"âœ… RandomForestRegressor fit+predict in {time.time()-t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c23c0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Linear Regression (Spending) complete.\n"
     ]
    }
   ],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 6.4 Linear Regression for Spending Prediction\n",
    "# # ----------------------------------------------------------\n",
    "lr_spending = LinearRegression()\n",
    "lr_spending.fit(X_spending_train_scaled, y_spending_train)\n",
    "\n",
    "y_spending_pred_lr = lr_spending.predict(X_spending_test_scaled)\n",
    "print(\"âœ… Linear Regression (Spending) complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f13a62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LinearSVC completed in 0.40s\n"
     ]
    }
   ],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 6.5 Linear SVM for Spending Prediction\n",
    "# # ----------------------------------------------------------\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "svm_spending = LinearSVC(\n",
    "    C=1.0,\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=2000,\n",
    "    tol=1e-3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm_spending.fit(X_spending_train_scaled, y_spending_train)\n",
    "y_spending_pred_svm = svm_spending.predict(X_spending_test_scaled)\n",
    "print(f\"âœ… LinearSVC completed in {time.time()-t0:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86415baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RandomForestClassifier fit+predict in 45.4s\n"
     ]
    }
   ],
   "source": [
    "# # -----------------------------------------------------------\n",
    "# # Step 6.6 Random Forest for Spending Prediction\n",
    "# # ----------------------------------------------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_spending = RandomForestClassifier(\n",
    "    n_estimators=150,        # keep modest to control runtime\n",
    "    max_depth=12,            # cap tree depth -> faster + less overfit\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=3,\n",
    "    max_features=\"sqrt\",\n",
    "    class_weight=\"balanced\", # helpful if classes are imbalanced\n",
    "    n_jobs=-1,               # use all CPUs in Codespaces\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_spending.fit(X_spending_train_scaled, y_spending_train)\n",
    "\n",
    "# class predictions (for accuracy / precision / recall / F1)\n",
    "y_spending_pred_rf = rf_spending.predict(X_spending_test_scaled)\n",
    "\n",
    "# probability scores (for ROC AUC, if you compute it later)\n",
    "y_spending_proba_rf = rf_spending.predict_proba(X_spending_test_scaled)[:, 1]\n",
    "print(f\"âœ… RandomForestClassifier fit+predict in {time.time()-t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d4b63",
   "metadata": {},
   "source": [
    "# 7. Evaluate Models\n",
    "We report regression metrics for Savings (MAE, MSE, RMSE, RÂ²) and classification metrics for Overspending (Accuracy, Precision, Recall, F1, plus a confusion matrix and full report). Where a model produced continuous scores (e.g., a regressor), we threshold at 0.5 to convert to 0/1 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6550fd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Savings â€” Regression Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1367.313447</td>\n",
       "      <td>4.752451e+06</td>\n",
       "      <td>2180.011716</td>\n",
       "      <td>0.926870</td>\n",
       "      <td>Linear Regression (Savings)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>178.402458</td>\n",
       "      <td>9.907168e+04</td>\n",
       "      <td>314.756537</td>\n",
       "      <td>0.998476</td>\n",
       "      <td>Random Forest (Savings)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MAE           MSE         RMSE        R2                        Model\n",
       "0  1367.313447  4.752451e+06  2180.011716  0.926870  Linear Regression (Savings)\n",
       "1   178.402458  9.907168e+04   314.756537  0.998476      Random Forest (Savings)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overspending â€” Classification Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVM (classifier)</td>\n",
       "      <td>0.991086</td>\n",
       "      <td>0.812416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (classifier)</td>\n",
       "      <td>0.990349</td>\n",
       "      <td>0.823193</td>\n",
       "      <td>0.955150</td>\n",
       "      <td>0.884275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression (classifier)</td>\n",
       "      <td>0.994998</td>\n",
       "      <td>0.983395</td>\n",
       "      <td>0.885382</td>\n",
       "      <td>0.931818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Accuracy  Precision    Recall        F1\n",
       "0           Linear SVM (classifier)  0.991086   0.812416  1.000000  0.896500\n",
       "1        Random Forest (classifier)  0.990349   0.823193  0.955150  0.884275\n",
       "2  Logistic Regression (classifier)  0.994998   0.983395  0.885382  0.931818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     29984\n",
      "           1       0.82      0.96      0.88      1204\n",
      "\n",
      "    accuracy                           0.99     31188\n",
      "   macro avg       0.91      0.97      0.94     31188\n",
      "weighted avg       0.99      0.99      0.99     31188\n",
      "\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>29737</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>54</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred 0  Pred 1\n",
       "Actual 0   29737     247\n",
       "Actual 1      54    1150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest ROC AUC: 0.998852\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 7. Evaluate Models\n",
    "#    - Regression (Savings):  MAE, MSE, RMSE, R^2\n",
    "#    - Classification (Overspending): Accuracy, Precision, Recall, F1\n",
    "#      + Confusion Matrix and classification report\n",
    "# ================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Helper functions\n",
    "# -------------------------------\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "def classification_metrics(y_true, y_pred, name=\"Model\"):\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "def safe_get(varname, default=None):\n",
    "    \"\"\"Safely fetch a variable from globals() if it exists.\"\"\"\n",
    "    return globals().get(varname, default)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# A) Savings (Regression) â€” summarize model metrics\n",
    "# -------------------------------------------------\n",
    "savings_summary = []\n",
    "y_true_sav = safe_get(\"y_savings_test\")\n",
    "\n",
    "if y_true_sav is None:\n",
    "    raise RuntimeError(\"y_savings_test not found in the notebook state.\")\n",
    "\n",
    "# Linear Regression\n",
    "y_hat_sav_lr = safe_get(\"y_savings_pred_lr\")\n",
    "if y_hat_sav_lr is not None:\n",
    "    sav_lr = regression_metrics(y_true_sav, y_hat_sav_lr)\n",
    "    sav_lr[\"Model\"] = \"Linear Regression (Savings)\"\n",
    "    savings_summary.append(sav_lr)\n",
    "\n",
    "# Random Forest\n",
    "y_hat_sav_rf = safe_get(\"y_savings_pred_rf\")\n",
    "if y_hat_sav_rf is not None:\n",
    "    sav_rf = regression_metrics(y_true_sav, y_hat_sav_rf)\n",
    "    sav_rf[\"Model\"] = \"Random Forest (Savings)\"\n",
    "    savings_summary.append(sav_rf)\n",
    "\n",
    "# Display regression summary\n",
    "if savings_summary:\n",
    "    print(\"Savings â€” Regression Metrics\")\n",
    "    display(pd.DataFrame(savings_summary))\n",
    "else:\n",
    "    print(\"No savings regression predictions found to evaluate.\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# B) Overspending (Classification) â€” summarize model performance\n",
    "# -------------------------------------------------------------------\n",
    "y_true_cls = safe_get(\"y_spending_test\")\n",
    "X_test_cls = safe_get(\"X_spending_test_scaled\")\n",
    "X_train_cls = safe_get(\"X_spending_train_scaled\")\n",
    "y_train_cls = safe_get(\"y_spending_train\")\n",
    "\n",
    "if y_true_cls is None:\n",
    "    raise RuntimeError(\"y_spending_test not found in the notebook state.\")\n",
    "\n",
    "cls_rows = []\n",
    "\n",
    "# Linear SVM\n",
    "y_pred_svm = safe_get(\"y_spending_pred_svm\")\n",
    "if y_pred_svm is not None:\n",
    "    cls_rows.append(classification_metrics(y_true_cls, y_pred_svm, \"Linear SVM (classifier)\"))\n",
    "\n",
    "# Random Forest\n",
    "y_pred_rf_cls = safe_get(\"y_spending_pred_rf\")\n",
    "if y_pred_rf_cls is not None:\n",
    "    cls_rows.append(classification_metrics(y_true_cls, y_pred_rf_cls, \"Random Forest (classifier)\"))\n",
    "\n",
    "# Logistic Regression (optional)\n",
    "y_pred_log_cls = safe_get(\"y_pred_log_cls\")\n",
    "log_clf = safe_get(\"log_clf\")\n",
    "\n",
    "if y_pred_log_cls is not None:\n",
    "    cls_rows.append(classification_metrics(y_true_cls, y_pred_log_cls, \"Logistic Regression (classifier)\"))\n",
    "elif (X_train_cls is not None) and (y_train_cls is not None) and (X_test_cls is not None):\n",
    "    try:\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        log_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        log_clf.fit(X_train_cls, y_train_cls)\n",
    "        y_pred_log_cls = log_clf.predict(X_test_cls)\n",
    "        cls_rows.append(classification_metrics(y_true_cls, y_pred_log_cls, \"Logistic Regression (classifier)\"))\n",
    "    except Exception as e:\n",
    "        print(f\"[Info] Could not (re)train Logistic Regression: {e}\")\n",
    "\n",
    "# Thresholded Linear Regression (if used for overspending)\n",
    "y_pred_lr_cont = safe_get(\"y_spending_pred_lr_cont\")\n",
    "if y_pred_lr_cont is not None:\n",
    "    y_pred_lr_bin = (np.array(y_pred_lr_cont) >= 0.5).astype(int)\n",
    "    cls_rows.append(classification_metrics(y_true_cls, y_pred_lr_bin, \"Linear Regression (thresholded)\"))\n",
    "\n",
    "# Display classification summary\n",
    "if cls_rows:\n",
    "    print(\"\\nOverspending â€” Classification Metrics\")\n",
    "    cls_df = pd.DataFrame(cls_rows)\n",
    "    display(cls_df)\n",
    "else:\n",
    "    print(\"No overspending classification predictions found to evaluate.\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# C) Detailed Report + Confusion Matrix for best model\n",
    "# -------------------------------------------------\n",
    "y_pred_for_report = None\n",
    "candidates = [\n",
    "    safe_get(\"y_spending_pred_rf\"),\n",
    "    safe_get(\"y_spending_pred_svm\"),\n",
    "    safe_get(\"y_pred_log_cls\"),\n",
    "    (np.array(safe_get(\"y_spending_pred_lr_cont\")) >= 0.5).astype(int)\n",
    "        if safe_get(\"y_spending_pred_lr_cont\") is not None else None\n",
    "]\n",
    "\n",
    "for cand in candidates:\n",
    "    if cand is not None:\n",
    "        y_pred_for_report = np.asarray(cand).ravel()  # ensure 1D\n",
    "        break\n",
    "\n",
    "if y_pred_for_report is not None:\n",
    "    print(\"\\nDetailed Classification Report\")\n",
    "    print(classification_report(y_true_cls, y_pred_for_report, zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(y_true_cls, y_pred_for_report)\n",
    "    cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Pred 0\", \"Pred 1\"])\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    display(cm_df)\n",
    "\n",
    "    # Try ROC AUC if probabilities available\n",
    "    auc_done = False\n",
    "    try:\n",
    "        rf_clf = safe_get(\"rf_spending\")\n",
    "        if rf_clf is not None and hasattr(rf_clf, \"predict_proba\"):\n",
    "            y_proba = rf_clf.predict_proba(X_test_cls)[:, 1]\n",
    "            print(f\"\\nRandom Forest ROC AUC: {roc_auc_score(y_true_cls, y_proba):.6f}\")\n",
    "            auc_done = True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if not auc_done:\n",
    "        log_clf = safe_get(\"log_clf\")\n",
    "        if log_clf is not None and hasattr(log_clf, \"predict_proba\"):\n",
    "            try:\n",
    "                y_proba = log_clf.predict_proba(X_test_cls)[:, 1]\n",
    "                print(f\"\\nLogistic Regression ROC AUC: {roc_auc_score(y_true_cls, y_proba):.6f}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "else:\n",
    "    print(\"\\nNo classification predictions available for the detailed report.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a343f",
   "metadata": {},
   "source": [
    "# 8. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5880c1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Regression Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RÂ²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression (Savings)</td>\n",
       "      <td>1367.306254</td>\n",
       "      <td>2180.012108</td>\n",
       "      <td>0.926870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (Savings)</td>\n",
       "      <td>197.318597</td>\n",
       "      <td>726.350473</td>\n",
       "      <td>0.991882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model          MAE         RMSE        RÂ²\n",
       "0  Linear Regression (Savings)  1367.306254  2180.012108  0.926870\n",
       "1      Random Forest (Savings)   197.318597   726.350473  0.991882"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Classification Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spending LR (thresholded)</td>\n",
       "      <td>0.961107</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.057498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.992529</td>\n",
       "      <td>0.860851</td>\n",
       "      <td>0.967585</td>\n",
       "      <td>0.911103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall        F1\n",
       "0  Spending LR (thresholded)  0.961107   0.698113  0.029984  0.057498\n",
       "1   Random Forest Classifier  0.992529   0.860851  0.967585  0.911103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Step 8: Summarize Model Performance (self-contained)\n",
    "# ===============================================================\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# ----- helpers -----\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"RÂ²\": r2}\n",
    "\n",
    "def classification_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\":  accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\":    recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1\":        f1_score(y_true, y_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "# ----- regression summary (savings prediction) -----\n",
    "reg_rows = []\n",
    "reg_rows.append({\"Model\": \"Linear Regression (Savings)\", **regression_metrics(y_savings_test, y_savings_pred_lr)})\n",
    "reg_rows.append({\"Model\": \"Random Forest (Savings)\",   **regression_metrics(y_savings_test, y_savings_pred_rf)})\n",
    "regression_results = pd.DataFrame(reg_rows)\n",
    "\n",
    "print(\"ðŸ“Š Regression Summary\")\n",
    "display(regression_results)\n",
    "\n",
    "# ----- classification summary (overspending detection) -----\n",
    "cls_rows = []\n",
    "cls_rows.append({\"Model\": \"Spending LR (thresholded)\", **classification_metrics(y_test_cls, y_pred_lr_bin)})\n",
    "cls_rows.append({\"Model\": \"Random Forest Classifier\",  **classification_metrics(y_test_cls, y_pred_rf_bin)})\n",
    "classification_results = pd.DataFrame(cls_rows)\n",
    "\n",
    "print(\"ðŸ“ˆ Classification Summary\")\n",
    "display(classification_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
